{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6uRbzW2XwAr"
      },
      "source": [
        "# **Import**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzG20hN9TSdr",
        "outputId": "ccfacda9-6c2d-4a0e-aad6-da3a3422695a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.9.2\n",
            "Keras version: 2.9.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import shutil\n",
        "import math\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import json \n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random as rd\n",
        "import pickle as pk\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n",
        "from time import time\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras import backend as K\n",
        "from skimage.feature import greycomatrix, greycoprops, local_binary_pattern\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input #224*224\n",
        "from keras.applications.xception import Xception, preprocess_input, decode_predictions #299*299\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions #224*224\n",
        "from tqdm import tqdm\n",
        "from keras_preprocessing.image import load_img, img_to_array\n",
        "print(\"Tensorflow version: \"+tf.__version__)\n",
        "print(\"Keras version: \" + tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLHgIIXBXckw"
      },
      "source": [
        "# **Database download**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QPFhmOHSTcv"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/sidimahmoudi/facenet_tf2/releases/download/AI_MIR_CLOUD/MIR_DATASETS_B.zip \n",
        "!unzip -q /content/MIR_DATASETS_B.zip\n",
        "!rm MIR_DATASETS_B.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV7QwUF4XsEV"
      },
      "source": [
        "# **Datbase preprocess**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jkeKbktnVD6M"
      },
      "outputs": [],
      "source": [
        "for animal in os.listdir('MIR_DATASETS_B'):\n",
        "  for type_animal in os.listdir(os.path.join('MIR_DATASETS_B', animal)):\n",
        "    for file in os.listdir(os.path.join('MIR_DATASETS_B', animal, type_animal)):\n",
        "      shutil.copy2(os.path.join('MIR_DATASETS_B', animal, type_animal, file), os.path.join('MIR_DATASETS_B'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbMmIegMX8oO"
      },
      "source": [
        "# **Indexation Deep Learning**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mstZ5kRLYCoF"
      },
      "outputs": [],
      "source": [
        "def dl_predict(filename, model, size):\n",
        "    img = load_img(filename, target_size = size)\n",
        "    img = img_to_array(img)\n",
        "    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
        "    img = preprocess_input(img)\n",
        "    feature = model.predict(img)\n",
        "    feature = np.array(feature[0])\n",
        "    return feature\n",
        "\n",
        "def generate(generate_func, source, output, last_layer = False):\n",
        "    start = time()\n",
        "    feature = generate_func(source, last_layer)\n",
        "    save(feature, output)\n",
        "    del feature\n",
        "    print(f'[INFO] Indexation : {generate_func.__name__} --> Done')\n",
        "    return round(time() - start, 3)\n",
        "\n",
        "def save(data, file_name):\n",
        "    with open(file_name, 'w') as f:\n",
        "        json.dump(data, f, cls = JsonCustomEncoder)\n",
        "\n",
        "class JsonCustomEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, (np.ndarray, np.number)):\n",
        "            return obj.tolist()\n",
        "        return json.JSONEncoder.default(self, obj)\n",
        "\n",
        "def VGG16_init(last_layer):\n",
        "    # https://keras.io/api/applications/vgg/\n",
        "    return VGG16(include_top = last_layer, weights ='imagenet', input_shape = (224, 224, 3), pooling = 'avg')\n",
        "\n",
        "def Xception_init(last_layer):\n",
        "    # https://keras.io/api/applications/xception/\n",
        "    return Xception(include_top = last_layer, weights ='imagenet', input_shape = (299, 299, 3), pooling = 'avg')\n",
        "\n",
        "def MobileNet_init(last_layer):\n",
        "    # https://keras.io/api/applications/mobilenet/\n",
        "    return MobileNet(include_top = last_layer, weights ='imagenet', input_shape = (224, 224, 3), pooling = 'avg')\n",
        "\n",
        "def generateVGG16(folder, last_layer):\n",
        "    model = VGG16_init(last_layer)\n",
        "    data = list()\n",
        "    for path in tqdm(os.listdir(folder)):\n",
        "      if '.jpg' in path:\n",
        "        feature = dl_predict(os.path.join(folder, path), model, (224, 224))\n",
        "        num_image, _ = path.split(\".\")\n",
        "        data.append({num_image : feature})\n",
        "    return data\n",
        "\n",
        "def generateXception(folder, last_layer):\n",
        "    model = Xception_init(last_layer)\n",
        "    data = list()\n",
        "    for path in tqdm(os.listdir(folder)):\n",
        "      if '.jpg' in path:\n",
        "        feature = dl_predict(os.path.join(folder, path), model, (299, 299))\n",
        "        num_image, _ = path.split(\".\")\n",
        "        data.append({num_image : feature})\n",
        "    return data\n",
        "\n",
        "def generateMobileNet(folder, last_layer):\n",
        "    model = MobileNet_init(last_layer)\n",
        "    data = list()\n",
        "    for path in tqdm(os.listdir(folder)):\n",
        "      if '.jpg' in path:\n",
        "        feature = dl_predict(os.path.join(folder, path), model, (224, 224))\n",
        "        num_image, _ = path.split(\".\")\n",
        "        data.append({num_image : feature})\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Yr8p_jWTa0O"
      },
      "outputs": [],
      "source": [
        "time_VGG16 = generate(generateVGG16, 'MIR_DATASETS_B/', 'VGG16_false.json', last_layer = False)\n",
        "time_Xcpetion = generate(generateXception, 'MIR_DATASETS_B/', 'XCEPTION_false.json', last_layer = False)\n",
        "time_MobileNet = generate(generateMobileNet, 'MIR_DATASETS_B/', 'MOBILENET_false.json', last_layer = False)\n",
        "time_Xcpetion_true = generate(generateXception, 'MIR_DATASETS_B/', 'XCEPTION_true.json', last_layer = True)\n",
        "\n",
        "with open('dl_time.json', 'w') as f:\n",
        "    t = {\n",
        "        'vgg16_false' : int(time_VGG16),\n",
        "        'xception_false' : int(time_Xcpetion),\n",
        "        'xception_true' : int(time_Xcpetion_true),\n",
        "          'mobilenet' : int(time_MobileNet)\n",
        "    }\n",
        "    json.dump(t, f, cls = JsonCustomEncoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HOHyvgiMfA6"
      },
      "source": [
        "# **Indexation PCA**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TSdlTBfsMky3"
      },
      "outputs": [],
      "source": [
        "def extractReqFeatures(folder, algo_choice, last_layer = False): \n",
        "    features_to_return = []              \n",
        "    if algo_choice == 'BGR':\n",
        "        for path in tqdm(os.listdir(folder)):\n",
        "            if '.jpg' in path:\n",
        "                img = cv2.imread(os.path.join(folder, path))\n",
        "                histB = cv2.calcHist([img],[0],None,[256],[0,256])\n",
        "                histG = cv2.calcHist([img],[1],None,[256],[0,256])\n",
        "                histR = cv2.calcHist([img],[2],None,[256],[0,256])\n",
        "                features_to_return.append(np.concatenate((histB, np.concatenate((histG,histR),axis=None)), axis=None))\n",
        "        return features_to_return\n",
        "    \n",
        "    elif algo_choice == 'HSV':\n",
        "        for path in tqdm(os.listdir(folder)):\n",
        "            if '.jpg' in path:\n",
        "                img = cv2.imread(os.path.join(folder, path))\n",
        "                hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
        "                histH = cv2.calcHist([hsv],[0],None,[180],[0,180])\n",
        "                histS = cv2.calcHist([hsv],[1],None,[256],[0,256])\n",
        "                histV = cv2.calcHist([hsv],[2],None,[256],[0,256])\n",
        "                features_to_return.append(np.concatenate((histH, np.concatenate((histS,histV),axis=None)), axis=None))\n",
        "        return features_to_return\n",
        "\n",
        "    elif algo_choice == 'SIFT':\n",
        "        for path in tqdm(os.listdir(folder)):\n",
        "            if '.jpg' in path:\n",
        "                img = cv2.imread(os.path.join(folder, path)) \n",
        "                w, h, c = img.shape\n",
        "                new_size = (int(w*0.3), int(h*0.3))\n",
        "                img = cv2.resize(img, new_size)\n",
        "                sift = cv2.SIFT_create()\n",
        "                kps , vect_features = sift.detectAndCompute(img,None)\n",
        "                features_to_return.append(vect_features)\n",
        "        return features_to_return\n",
        "\n",
        "    elif algo_choice == 'ORB':\n",
        "        for path in tqdm(os.listdir(folder)):\n",
        "            if '.jpg' in path:\n",
        "                img = cv2.imread(os.path.join(folder, path))  \n",
        "                orb = cv2.ORB_create()\n",
        "                key_point1, vect_features = orb.detectAndCompute(img,None)\n",
        "                features_to_return.append(vect_features)\n",
        "        return features_to_return\n",
        "\n",
        "    elif algo_choice == 'GLCM': \n",
        "        for path in tqdm(os.listdir(folder)):\n",
        "            if '.jpg' in path:\n",
        "                img = cv2.imread(os.path.join(folder, path)) \n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                glcm = greycomatrix(img, distances=[1, -1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], normed=True)\n",
        "                glcmProperties1 = greycoprops(glcm,'contrast').ravel()\n",
        "                glcmProperties2 = greycoprops(glcm,'dissimilarity').ravel()\n",
        "                glcmProperties3 = greycoprops(glcm,'homogeneity').ravel()\n",
        "                glcmProperties4 = greycoprops(glcm,'energy').ravel()\n",
        "                glcmProperties5 = greycoprops(glcm,'correlation').ravel()\n",
        "                glcmProperties6 = greycoprops(glcm,'ASM').ravel()\n",
        "                feat =  np.array([glcmProperties1,\n",
        "                                        glcmProperties2,\n",
        "                                        glcmProperties3,\n",
        "                                        glcmProperties4,\n",
        "                                        glcmProperties5,\n",
        "                                        glcmProperties6]).ravel()\n",
        "                features_to_return.append(feat)\n",
        "        return features_to_return\n",
        "    elif algo_choice == 'LBP':\n",
        "        for path in tqdm(os.listdir(folder)):\n",
        "            if '.jpg' in path:\n",
        "                img = cv2.imread(os.path.join(folder, path)) \n",
        "                points=8\n",
        "                radius=1\n",
        "                method='default'\n",
        "                subSize=(70,70)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                img = cv2.resize(img,(350,350))\n",
        "                fullLBPmatrix = local_binary_pattern(img,points,radius,method)\n",
        "                hist = []\n",
        "                for k in range(int(fullLBPmatrix.shape[0]/subSize[0])):\n",
        "                    for j in range(int(fullLBPmatrix.shape[1]/subSize[1])):\n",
        "                        subVector = fullLBPmatrix[k*subSize[0]:(k+1)*subSize[0],j*subSize[1]:(j+1)*subSize[1]].ravel()\n",
        "                        subHist,edges = np.histogram(subVector,bins=int(2**points),range=(0,2**points))\n",
        "                        hist = np.concatenate((hist, subHist), axis=None)\n",
        "                features_to_return.append(hist)\n",
        "        return features_to_return\n",
        "\n",
        "    elif algo_choice == 'HOG':\n",
        "        for path in tqdm(os.listdir(folder)):\n",
        "            if '.jpg' in path:\n",
        "                img = cv2.imread(os.path.join(folder, path)) \n",
        "                cellSize = (25,25)\n",
        "                blockSize = (50,50)\n",
        "                blockStride = (25,25)\n",
        "                nBins = 9\n",
        "                winSize = (350,350)\n",
        "                image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "                image = cv2.resize(image,winSize)\n",
        "                hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nBins)\n",
        "                features_to_return.append(hog.compute(image))\n",
        "        return features_to_return\n",
        "\n",
        "    elif algo_choice == 'VGG16':\n",
        "        model = VGG16(include_top = last_layer, weights ='imagenet', input_shape = (224, 224, 3), pooling = 'avg')\n",
        "        for path in tqdm(os.listdir(folder)):\n",
        "            if '.jpg' in path:\n",
        "                img = load_img(os.path.join(folder, path), target_size = (224, 224))\n",
        "                img = img_to_array(img)\n",
        "                img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
        "                img = preprocess_input(img)\n",
        "                feature = model.predict(img)\n",
        "                features_to_return.append(np.array(feature[0]))\n",
        "        return features_to_return\n",
        "\n",
        "    elif algo_choice == 'XCEPTION':\n",
        "        model = Xception(include_top = last_layer, weights ='imagenet', input_shape = (299, 299, 3), pooling = 'avg')\n",
        "        for path in tqdm(os.listdir(folder)):\n",
        "            if '.jpg' in path:\n",
        "                img = load_img(os.path.join(folder, path), target_size = (299, 299))\n",
        "                img = img_to_array(img)\n",
        "                img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
        "                img = preprocess_input(img)\n",
        "                feature = model.predict(img)\n",
        "                features_to_return.append(np.array(feature[0]))\n",
        "        return features_to_return\n",
        "\n",
        "    elif algo_choice == 'MOBILENET':\n",
        "        model = MobileNet(include_top = last_layer, weights ='imagenet', input_shape = (224, 224, 3), pooling = 'avg')\n",
        "        for path in tqdm(os.listdir(folder)):\n",
        "            if '.jpg' in path:\n",
        "                img = load_img(os.path.join(folder, path), target_size = (224, 224))\n",
        "                img = img_to_array(img)\n",
        "                img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
        "                img = preprocess_input(img)\n",
        "                feature = model.predict(img)\n",
        "                features_to_return.append(np.array(feature[0]))\n",
        "        return features_to_return\n",
        "\n",
        "def pca_generate(folder, algo, last_layer, file_output):\n",
        "  start_feature = time()\n",
        "  data = extractReqFeatures(folder, algo, last_layer)\n",
        "  end_feature = time()\n",
        "  \n",
        "  name = [path.split(\".\")[0] for path in os.listdir(folder) if '.jpg' in path]\n",
        "\n",
        "  start_pca = time()\n",
        "  pca = PCA()\n",
        "  pk.dump(pca, open(file_output + '.pkl','wb'))\n",
        "  pca_data = pca.transform(data)\n",
        "  end_pca = time()\n",
        "\n",
        "  start_json = time()\n",
        "  data_json = list()\n",
        "  for pca_feature, pca_name in zip(pca_data, name):\n",
        "    data_json.append({pca_name : pca_feature})\n",
        "  with open(file_output + '.json', 'w') as f:\n",
        "      json.dump(data_json, f, cls = JsonCustomEncoder)\n",
        "  end_json = time()\n",
        "\n",
        "  with open(file_output + '_time.json', 'w') as f:\n",
        "      t = {\n",
        "          'extract_feature' : int(end_feature - start_feature),\n",
        "          'pca' : int(end_pca - start_pca),\n",
        "          'json dump' : int(end_json - start_json)\n",
        "      }\n",
        "      json.dump(t, f, cls = JsonCustomEncoder)\n",
        "\n",
        "class JsonCustomEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, (np.ndarray, np.number)):\n",
        "            return obj.tolist()\n",
        "        return json.JSONEncoder.default(self, obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mSHn21BPp_-"
      },
      "outputs": [],
      "source": [
        "pca_generate('MIR_DATASETS_B/', 'XCEPTION', False, 'XCEPTION_false_pca')\n",
        "pca_generate('MIR_DATASETS_B/', 'XCEPTION', True, 'XCEPTION_true_pca')\n",
        "pca_generate('MIR_DATASETS_B/', 'MOBILENET', False, 'MOBILENET_false_pca')\n",
        "pca_generate('MIR_DATASETS_B/', 'VGG16', False, 'VGG16_false_pca')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "c4981c284bbb39c2a23436697d7c35c93923ac1f7e5eb9a1ba9ec845d3dcf5ee"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
