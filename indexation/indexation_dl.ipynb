{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6uRbzW2XwAr"
      },
      "source": [
        "# **Import**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzG20hN9TSdr",
        "outputId": "5ede5cd7-4ff1-4679-b445-2c0207c142a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.9.2\n",
            "Keras version: 2.9.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import shutil\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import json \n",
        "\n",
        "from time import time\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input #224*224\n",
        "from keras.applications.xception import Xception, preprocess_input, decode_predictions #299*299\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions #224*224\n",
        "from tqdm import tqdm\n",
        "from keras_preprocessing.image import load_img\n",
        "from keras_preprocessing.image import img_to_array\n",
        "print(\"Tensorflow version: \"+tf.__version__)\n",
        "print(\"Keras version: \" + tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLHgIIXBXckw"
      },
      "source": [
        "# **Database download**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QPFhmOHSTcv"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/sidimahmoudi/facenet_tf2/releases/download/AI_MIR_CLOUD/MIR_DATASETS_B.zip \n",
        "!unzip -q /content/MIR_DATASETS_B.zip\n",
        "!rm MIR_DATASETS_B.zip\n",
        "!rm -f sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV7QwUF4XsEV"
      },
      "source": [
        "# **Datbase preprocess**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jkeKbktnVD6M"
      },
      "outputs": [],
      "source": [
        "for animal in os.listdir('MIR_DATASETS_B'):\n",
        "  for type_animal in os.listdir(os.path.join('MIR_DATASETS_B', animal)):\n",
        "    for file in os.listdir(os.path.join('MIR_DATASETS_B', animal, type_animal)):\n",
        "      shutil.copy2(os.path.join('MIR_DATASETS_B', animal, type_animal, file), os.path.join('MIR_DATASETS_B'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbMmIegMX8oO"
      },
      "source": [
        "# **Indexation in JSON**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mstZ5kRLYCoF"
      },
      "outputs": [],
      "source": [
        "def dl_predict(filename, model, size):\n",
        "    img = load_img(filename, target_size = size)\n",
        "    img = img_to_array(img)\n",
        "    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
        "    img = preprocess_input(img)\n",
        "    feature = model.predict(img)\n",
        "    feature = np.array(feature[0])\n",
        "    return feature\n",
        "\n",
        "def generate(generate_func, source, output):\n",
        "    start = time()\n",
        "    feature = generate_func(source)\n",
        "    save(feature, output)\n",
        "    del feature\n",
        "    print(f'[INFO] Indexation : {generate_func.__name__} --> Done')\n",
        "    return round(time() - start, 3)\n",
        "\n",
        "def save(data, file_name):\n",
        "    with open(file_name, 'w') as f:\n",
        "        json.dump(data, f, cls = JsonCustomEncoder)\n",
        "\n",
        "class JsonCustomEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, (np.ndarray, np.number)):\n",
        "            return obj.tolist()\n",
        "        return json.JSONEncoder.default(self, obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JvobYQw5YIBg"
      },
      "outputs": [],
      "source": [
        "def VGG16_init():\n",
        "    # https://keras.io/api/applications/vgg/\n",
        "    return VGG16(include_top = False, weights ='imagenet', input_shape = (224, 224, 3), pooling = 'avg')\n",
        "\n",
        "def Xception_init():\n",
        "    # https://keras.io/api/applications/xception/\n",
        "    return Xception(include_top = False, weights ='imagenet', input_shape = (299, 299, 3), pooling = 'avg')\n",
        "\n",
        "def MobileNet_init():\n",
        "    # https://keras.io/api/applications/mobilenet/\n",
        "    return MobileNet(include_top = True, weights ='imagenet', input_shape = (224, 224, 3), pooling = 'avg')\n",
        "\n",
        "def generateVGG16(folder):\n",
        "    model = VGG16_init()\n",
        "    data = list()\n",
        "    for path in tqdm(os.listdir(folder)):\n",
        "      if '.jpg' in path:\n",
        "        feature = dl_predict(os.path.join(folder, path), model, (224, 224))\n",
        "        num_image, _ = path.split(\".\")\n",
        "        data.append({num_image : feature})\n",
        "    return data\n",
        "\n",
        "def generateXception(folder):\n",
        "    model = Xception_init()\n",
        "    data = list()\n",
        "    for path in tqdm(os.listdir(folder)):\n",
        "      if '.jpg' in path:\n",
        "        feature = dl_predict(os.path.join(folder, path), model, (299, 299))\n",
        "        num_image, _ = path.split(\".\")\n",
        "        data.append({num_image : feature})\n",
        "    return data\n",
        "\n",
        "def generateMobileNet(folder):\n",
        "    model = MobileNet_init()\n",
        "    data = list()\n",
        "    for path in tqdm(os.listdir(folder)):\n",
        "      if '.jpg' in path:\n",
        "        feature = dl_predict(os.path.join(folder, path), model, (224, 224))\n",
        "        num_image, _ = path.split(\".\")\n",
        "        data.append({num_image : feature})\n",
        "    return data\n",
        "    \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Yr8p_jWTa0O"
      },
      "outputs": [],
      "source": [
        "time_VGG16 = generate(generateVGG16, 'MIR_DATASETS_B/', 'VGG16.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QC8lrI8z1znW"
      },
      "outputs": [],
      "source": [
        "time_Xcpetion = generate(generateXception, 'MIR_DATASETS_B/', 'XCEPTION.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aPpVlaV2_A5"
      },
      "outputs": [],
      "source": [
        "time_MobileNet = generate(generateMobileNet, 'MIR_DATASETS_B/', 'MOBILENET.json')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "c4981c284bbb39c2a23436697d7c35c93923ac1f7e5eb9a1ba9ec845d3dcf5ee"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
